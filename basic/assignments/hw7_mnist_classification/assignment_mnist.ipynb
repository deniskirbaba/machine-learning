{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №7\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №1: \n",
    "Обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку первого занятия.\n",
    "\n",
    "Настоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на готовые примеры, а не просто \"скопировать-вставить\". Это поможет вам в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 92% accuracy.\n",
    "\n",
    "*Комментарий: для этого достаточно линейных слоев и функций активации.*\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model`.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mnist_data), len(test_mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]),\n",
       " array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(train_mnist_data.targets), np.bincount(test_mnist_data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([784]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist_data.data.shape, train_mnist_data.data[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   9,  11,  14,  16,  18,  23,  24,  25,  26,\n",
       "        27,  30,  35,  36,  39,  43,  45,  46,  49,  55,  56,  64,  66,\n",
       "        70,  78,  80,  81,  82,  90,  93,  94, 107, 108, 114, 119, 126,\n",
       "       127, 130, 132, 133, 135, 136, 139, 148, 150, 154, 156, 160, 166,\n",
       "       170, 171, 172, 175, 182, 183, 186, 187, 190, 195, 198, 201, 205,\n",
       "       207, 212, 213, 219, 221, 225, 226, 229, 238, 240, 241, 242, 244,\n",
       "       247, 249, 250, 251, 252, 253, 255], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_mnist_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_mnist_data.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*8, 32, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "                        \n",
    "            nn.Linear(32, 10, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout2d(p=0.5, inplace=False)\n",
      "    (5): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=392, out_features=32, bias=False)\n",
      "    (10): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.425769  [    0/60000]\n",
      "loss: 2.222697  [ 3200/60000]\n",
      "loss: 2.105215  [ 6400/60000]\n",
      "loss: 1.792469  [ 9600/60000]\n",
      "loss: 1.885800  [12800/60000]\n",
      "loss: 1.764047  [16000/60000]\n",
      "loss: 1.777979  [19200/60000]\n",
      "loss: 1.534490  [22400/60000]\n",
      "loss: 1.556844  [25600/60000]\n",
      "loss: 1.450294  [28800/60000]\n",
      "loss: 1.324183  [32000/60000]\n",
      "loss: 1.427638  [35200/60000]\n",
      "loss: 1.357113  [38400/60000]\n",
      "loss: 1.263776  [41600/60000]\n",
      "loss: 1.436810  [44800/60000]\n",
      "loss: 1.252240  [48000/60000]\n",
      "loss: 1.290265  [51200/60000]\n",
      "loss: 1.289184  [54400/60000]\n",
      "loss: 1.215808  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 1.124379 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.123289  [    0/60000]\n",
      "loss: 0.993337  [ 3200/60000]\n",
      "loss: 1.105442  [ 6400/60000]\n",
      "loss: 1.156391  [ 9600/60000]\n",
      "loss: 1.160642  [12800/60000]\n",
      "loss: 0.996785  [16000/60000]\n",
      "loss: 1.150614  [19200/60000]\n",
      "loss: 1.020607  [22400/60000]\n",
      "loss: 0.997909  [25600/60000]\n",
      "loss: 1.007418  [28800/60000]\n",
      "loss: 0.818181  [32000/60000]\n",
      "loss: 0.882958  [35200/60000]\n",
      "loss: 1.044065  [38400/60000]\n",
      "loss: 1.041251  [41600/60000]\n",
      "loss: 0.885626  [44800/60000]\n",
      "loss: 0.858712  [48000/60000]\n",
      "loss: 0.896206  [51200/60000]\n",
      "loss: 0.916526  [54400/60000]\n",
      "loss: 0.788582  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.748382 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.888079  [    0/60000]\n",
      "loss: 0.677709  [ 3200/60000]\n",
      "loss: 0.754539  [ 6400/60000]\n",
      "loss: 0.802549  [ 9600/60000]\n",
      "loss: 0.710169  [12800/60000]\n",
      "loss: 0.948538  [16000/60000]\n",
      "loss: 0.762859  [19200/60000]\n",
      "loss: 0.631658  [22400/60000]\n",
      "loss: 0.652567  [25600/60000]\n",
      "loss: 0.745826  [28800/60000]\n",
      "loss: 0.507502  [32000/60000]\n",
      "loss: 0.871003  [35200/60000]\n",
      "loss: 0.615028  [38400/60000]\n",
      "loss: 0.452342  [41600/60000]\n",
      "loss: 0.530925  [44800/60000]\n",
      "loss: 0.627411  [48000/60000]\n",
      "loss: 0.538759  [51200/60000]\n",
      "loss: 0.447661  [54400/60000]\n",
      "loss: 0.503077  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.512812 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.713769  [    0/60000]\n",
      "loss: 0.448938  [ 3200/60000]\n",
      "loss: 0.647294  [ 6400/60000]\n",
      "loss: 0.572054  [ 9600/60000]\n",
      "loss: 0.574738  [12800/60000]\n",
      "loss: 0.625278  [16000/60000]\n",
      "loss: 0.516459  [19200/60000]\n",
      "loss: 0.696693  [22400/60000]\n",
      "loss: 0.591404  [25600/60000]\n",
      "loss: 0.639477  [28800/60000]\n",
      "loss: 0.619665  [32000/60000]\n",
      "loss: 0.589877  [35200/60000]\n",
      "loss: 0.682733  [38400/60000]\n",
      "loss: 0.506212  [41600/60000]\n",
      "loss: 0.612794  [44800/60000]\n",
      "loss: 0.507967  [48000/60000]\n",
      "loss: 0.559465  [51200/60000]\n",
      "loss: 0.427347  [54400/60000]\n",
      "loss: 0.348922  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.402525 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.513693  [    0/60000]\n",
      "loss: 0.374982  [ 3200/60000]\n",
      "loss: 0.428821  [ 6400/60000]\n",
      "loss: 0.439592  [ 9600/60000]\n",
      "loss: 0.426124  [12800/60000]\n",
      "loss: 0.443150  [16000/60000]\n",
      "loss: 0.417227  [19200/60000]\n",
      "loss: 0.480250  [22400/60000]\n",
      "loss: 0.697531  [25600/60000]\n",
      "loss: 0.407334  [28800/60000]\n",
      "loss: 0.548997  [32000/60000]\n",
      "loss: 0.718218  [35200/60000]\n",
      "loss: 0.519845  [38400/60000]\n",
      "loss: 0.487576  [41600/60000]\n",
      "loss: 0.447074  [44800/60000]\n",
      "loss: 0.343224  [48000/60000]\n",
      "loss: 0.505664  [51200/60000]\n",
      "loss: 0.467835  [54400/60000]\n",
      "loss: 0.254423  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.327393 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_data_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_data_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_data_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_data_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model is not None, 'Please, use `model` variable to store your model'\n",
    "\n",
    "try:\n",
    "    x = random_batch[0]\n",
    "    y = random_batch[1]\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model(x)    \n",
    "except Exception as e:\n",
    "    print('Something is wrong with the model')\n",
    "    raise e\n",
    "    \n",
    "    \n",
    "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
    "\n",
    "print('Everything seems fine!')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0])\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.92978\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0])\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9381\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
    "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
