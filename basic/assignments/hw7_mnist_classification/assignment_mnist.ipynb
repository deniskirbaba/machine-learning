{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №7\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №1: \n",
    "Обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку первого занятия.\n",
    "\n",
    "Настоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на готовые примеры, а не просто \"скопировать-вставить\". Это поможет вам в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 5')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 92% accuracy.\n",
    "\n",
    "*Комментарий: для этого достаточно линейных слоев и функций активации.*\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model`.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mnist_data), len(test_mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]),\n",
       " array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(train_mnist_data.targets), np.bincount(test_mnist_data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([784]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist_data.data.shape, train_mnist_data.data[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   9,  11,  14,  16,  18,  23,  24,  25,  26,\n",
       "        27,  30,  35,  36,  39,  43,  45,  46,  49,  55,  56,  64,  66,\n",
       "        70,  78,  80,  81,  82,  90,  93,  94, 107, 108, 114, 119, 126,\n",
       "       127, 130, 132, 133, 135, 136, 139, 148, 150, 154, 156, 160, 166,\n",
       "       170, 171, 172, 175, 182, 183, 186, 187, 190, 195, 198, 201, 205,\n",
       "       207, 212, 213, 219, 221, 225, 226, 229, 238, 240, 241, 242, 244,\n",
       "       247, 249, 250, 251, 252, 253, 255], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_mnist_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_mnist_data.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*32, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.Linear(128, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.GELU(),\n",
    "                        \n",
    "            nn.Linear(32, 10, bias=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): GELU(approximate='none')\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=1568, out_features=128, bias=True)\n",
      "    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): GELU(approximate='none')\n",
      "    (12): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (13): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): GELU(approximate='none')\n",
      "    (15): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.451320  [    0/60000]\n",
      "loss: 2.015200  [ 3200/60000]\n",
      "loss: 1.554134  [ 6400/60000]\n",
      "loss: 1.556318  [ 9600/60000]\n",
      "loss: 1.247288  [12800/60000]\n",
      "loss: 1.106646  [16000/60000]\n",
      "loss: 1.265905  [19200/60000]\n",
      "loss: 1.012833  [22400/60000]\n",
      "loss: 0.762989  [25600/60000]\n",
      "loss: 0.849062  [28800/60000]\n",
      "loss: 0.822956  [32000/60000]\n",
      "loss: 0.740996  [35200/60000]\n",
      "loss: 0.692632  [38400/60000]\n",
      "loss: 0.835200  [41600/60000]\n",
      "loss: 0.759757  [44800/60000]\n",
      "loss: 0.719754  [48000/60000]\n",
      "loss: 0.863397  [51200/60000]\n",
      "loss: 0.758416  [54400/60000]\n",
      "loss: 0.589393  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.529138 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.624068  [    0/60000]\n",
      "loss: 0.480292  [ 3200/60000]\n",
      "loss: 0.453246  [ 6400/60000]\n",
      "loss: 0.672654  [ 9600/60000]\n",
      "loss: 0.597430  [12800/60000]\n",
      "loss: 0.514049  [16000/60000]\n",
      "loss: 0.394518  [19200/60000]\n",
      "loss: 0.491941  [22400/60000]\n",
      "loss: 0.431154  [25600/60000]\n",
      "loss: 0.468489  [28800/60000]\n",
      "loss: 0.558208  [32000/60000]\n",
      "loss: 0.487730  [35200/60000]\n",
      "loss: 0.361925  [38400/60000]\n",
      "loss: 0.410783  [41600/60000]\n",
      "loss: 0.332946  [44800/60000]\n",
      "loss: 0.330279  [48000/60000]\n",
      "loss: 0.427073  [51200/60000]\n",
      "loss: 0.356109  [54400/60000]\n",
      "loss: 0.465540  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.315110 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.265661  [    0/60000]\n",
      "loss: 0.291829  [ 3200/60000]\n",
      "loss: 0.350909  [ 6400/60000]\n",
      "loss: 0.289117  [ 9600/60000]\n",
      "loss: 0.213437  [12800/60000]\n",
      "loss: 0.377183  [16000/60000]\n",
      "loss: 0.330463  [19200/60000]\n",
      "loss: 0.308925  [22400/60000]\n",
      "loss: 0.273836  [25600/60000]\n",
      "loss: 0.233474  [28800/60000]\n",
      "loss: 0.352707  [32000/60000]\n",
      "loss: 0.302802  [35200/60000]\n",
      "loss: 0.410356  [38400/60000]\n",
      "loss: 0.565159  [41600/60000]\n",
      "loss: 0.244195  [44800/60000]\n",
      "loss: 0.292976  [48000/60000]\n",
      "loss: 0.254455  [51200/60000]\n",
      "loss: 0.368600  [54400/60000]\n",
      "loss: 0.347939  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.236843 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.186097  [    0/60000]\n",
      "loss: 0.284026  [ 3200/60000]\n",
      "loss: 0.182859  [ 6400/60000]\n",
      "loss: 0.244841  [ 9600/60000]\n",
      "loss: 0.482037  [12800/60000]\n",
      "loss: 0.319384  [16000/60000]\n",
      "loss: 0.278030  [19200/60000]\n",
      "loss: 0.159805  [22400/60000]\n",
      "loss: 0.339531  [25600/60000]\n",
      "loss: 0.366965  [28800/60000]\n",
      "loss: 0.228867  [32000/60000]\n",
      "loss: 0.199085  [35200/60000]\n",
      "loss: 0.321895  [38400/60000]\n",
      "loss: 0.334719  [41600/60000]\n",
      "loss: 0.188382  [44800/60000]\n",
      "loss: 0.473879  [48000/60000]\n",
      "loss: 0.165462  [51200/60000]\n",
      "loss: 0.120653  [54400/60000]\n",
      "loss: 0.133989  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.194469 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.250919  [    0/60000]\n",
      "loss: 0.396305  [ 3200/60000]\n",
      "loss: 0.214679  [ 6400/60000]\n",
      "loss: 0.587391  [ 9600/60000]\n",
      "loss: 0.110231  [12800/60000]\n",
      "loss: 0.354772  [16000/60000]\n",
      "loss: 0.203215  [19200/60000]\n",
      "loss: 0.147721  [22400/60000]\n",
      "loss: 0.290469  [25600/60000]\n",
      "loss: 0.228813  [28800/60000]\n",
      "loss: 0.204601  [32000/60000]\n",
      "loss: 0.221391  [35200/60000]\n",
      "loss: 0.238373  [38400/60000]\n",
      "loss: 0.310636  [41600/60000]\n",
      "loss: 0.112256  [44800/60000]\n",
      "loss: 0.329016  [48000/60000]\n",
      "loss: 0.233525  [51200/60000]\n",
      "loss: 0.154195  [54400/60000]\n",
      "loss: 0.258042  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.168004 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_data_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_data_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.354582  [    0/60000]\n",
      "loss: 0.460311  [ 3200/60000]\n",
      "loss: 0.204952  [ 6400/60000]\n",
      "loss: 0.155318  [ 9600/60000]\n",
      "loss: 0.064115  [12800/60000]\n",
      "loss: 0.098630  [16000/60000]\n",
      "loss: 0.083809  [19200/60000]\n",
      "loss: 0.055163  [22400/60000]\n",
      "loss: 0.064447  [25600/60000]\n",
      "loss: 0.072186  [28800/60000]\n",
      "loss: 0.011762  [32000/60000]\n",
      "loss: 0.237685  [35200/60000]\n",
      "loss: 0.064070  [38400/60000]\n",
      "loss: 0.015632  [41600/60000]\n",
      "loss: 0.005191  [44800/60000]\n",
      "loss: 0.027454  [48000/60000]\n",
      "loss: 0.025386  [51200/60000]\n",
      "loss: 0.011160  [54400/60000]\n",
      "loss: 0.186818  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.039664 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.028159  [    0/60000]\n",
      "loss: 0.004208  [ 3200/60000]\n",
      "loss: 0.036526  [ 6400/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     train_loop(train_data_loader, model, loss_fn, optimizer)\n\u001b[1;32m      7\u001b[0m     test_loop(test_data_loader, model, loss_fn)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 30\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:178\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    184\u001b[0m     bn_training,\n\u001b[1;32m    185\u001b[0m     exponential_average_factor,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    187\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1696\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1698\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_data_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_data_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something is wrong with the model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [32, 784]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSomething is wrong with the model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m y_predicted\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel should predict 10 logits/probas\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEverything seems fine!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     y \u001b[38;5;241m=\u001b[39m random_batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# compute outputs given inputs, both are variables\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     y_predicted \u001b[38;5;241m=\u001b[39m model(x)    \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSomething is wrong with the model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 30\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [32, 784]"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model is not None, 'Please, use `model` variable to store your model'\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].reshape(-1, 784)\n",
    "    y = random_batch[1]\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model(x)    \n",
    "except Exception as e:\n",
    "    print('Something is wrong with the model')\n",
    "    raise e\n",
    "    \n",
    "    \n",
    "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
    "\n",
    "print('Everything seems fine!')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройте параметры модели на обучающей выборке. Рекомендуем поработать с различными оптимизаторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0])#.reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.99278\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0])#.reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9901\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
    "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Загрузите файл `hw07_data_dict.npy` (ссылка есть на странице с заданием) и запустите код ниже для генерации посылки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_hw07.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "import json\n",
    "assert os.path.exists('hw07_data_dict.npy'), 'Please, download `hw07_data_dict.npy` and place it in the working directory'\n",
    "\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "    \n",
    "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
    "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "loaded_data_dict = np.load('hw07_data_dict.npy', allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
    "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
    "}\n",
    "\n",
    "with open('submission_dict_hw07.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print('File saved to `submission_dict_hw07.json`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
