# Gradient Boosting

https://catboost.ai/en/docs/concepts/algorithm-score-functions#gradient-boosting - good material (catboost)

RF строит модели параллельно, но логично что можно это делать и последовательно.
Как можно "подключить" модели последовательно?
Интуиция следующая: будем увеличивать вклад ошибки на неверном объекте в итоговой функции потерь. То есть добавим к ошибке на каждом объекте некоторый вес $\omega_i$. И на каждом шаге последовательности (моделей) будем перерасчитывать эти веса. В конце мы каким-то образом аггрегируем эти последовательные модели, получив финальную модель.

# Boosting: AdaBoost
Тут используется экспоненциальная функция потерь: $E(M) = e^{-M}$.
Итоговая модель расписывается как: $f(x) = \Sum \rho_t h_t(x)$. Где $\rho$ - коэффициенты вкладов базовых моделей $h_t(x)$. При расчете функции потерь для определенного объекта, мы получим, что эта функция равна константе (так как все прошлые модели уже внесли свой вклад и мы уже вычислили на прошлых шагах это слагаемое) и экспоненциальной функции потерь на последней базовой модели.

Стоит отметить, что в качестве базовых моделей могут быть абсолютно любые модели. Однако экспоненциальная функция потерь - крайне опасная штука, так как если мы на каком-то объекты имеет большую ошибку, будет пробелмы при экспоненцировании.

AdaBoost это не градиентный бустинг - это его частный случай!
Этих различных вариаций бустинга было огромное множество, до тех пор пока Фридман не предложил идею градиентного бустинга.

# Gradient Boosting
Пусть у нас есть выборка $(x_i, y_i)$, функция потерь $L$ и наша задача найти такую оптимальную модель $f^^(x)$, которая будет минимизировать функцию эмпирического риска на обучающей выборке, а так же на той зависимости на которой в дальнейшем мы будем работать (валидационная, генеральная и тд). 
Пусть у нас есть параметрическое семейство зависимостей $f(x, \theta^^)$, тогда мы будем искать argmin по параметру $\theta^^$ для минимизации функции эмпирического риска.

Мы можем применять градиентный спуск в пространстве базовых моделей (по параметру $\theta$). То есть на каждом шаге мы сможем находить оптимальную модель. Однако для этого там требуется такие модели, для которых мы можем применять градиентные методы (например, деревья не подойдут). 

Итого все модели можно записать как: $f^^_{T-1}(x) = \Sum_{t = 0}^{T-1} g_t(x)$, где $g_t(x) = \rho_t h(x, \theta_t)$ - базовые модели. Финальная модель будет иметь вид: $f^^_T(x) = \rho_T h(x, \theta_T)$. 

Представим функциональное пространство, то есть пространство отображений $X -> Y$, где каждый объект в пространстве является отображением. Пусть каждая точка в этом пространстве соответствует какой-то итоговой модели и мы бы в этом пространстве могли использовать градиентный спуск. 

Попробуем применить градиентный спуск для такого последовательного ансамбля. 

То есть вспомним как записывался градиентный спуск в линейной регрессии: там была взвешенная сумма по градиенту от функции потерь для весов: $\omega_T = \omega_0 - \eta \Sum_{i=0}^T grad_{\omega_i} L$. А у нас по сути финальная модель есть взвешенная сумма по базовым моделям: $f^^_{T}(x) = \Sum_{t = 0}^{T} \rho_t h(x, \theta_t)$.

В градиентном спуске мы ищем куда бы изменить значения параметров, чтобы понизить ошибку наилучшем образом. А в случае градиентного бустинга мы смотрит как бы изменить предсказания модели, чтобы понизить ошибку.

Будем использовать модель, чтобы аппроксимировать (делать некоторую оценку) антиградиент функции потерь по предсказаниям. 

Затем дифференцируем функцию потерь по предсказаниям модели, тем самым найдя антиградиент функции ошибки по предсказанию $r_t$.
Таким образом мы для каждого объекта $x^{(i)}$ имеем истинное значение $y^{(i)}$, имеем значение предсказания модели на шаге $t$, которое равно $f_t(x^{(i)})$ и имеем антиградиент функции ошибки по предсказанию для этого объекта $r_t^{(i)}$.

Теперь, так как у нас есть антиградиент функции ошибки по предсказанию на каждом шаге $t$, мы будем принимать его в качестве таргета для модели на шаге $t+1$. То есть на шаге $t$ мы будем с помощью новой модели обучать отображение не из $X$ в $Y$, а из $X$ в антиградиент ошибки на этом $X$. Таким образом, мы на каждом шаге с помощью таких моделей будем приближать антиградиент для уменьшения функции эмпирического риска. И на каждом шаге мы будем добавлять модель в ансамбль, которая будет аппроксимировать антиградиент.

Также, следует указать, что в тот момент когда мы сказали что будем аппроксимировать антиградиент функции потерь каждой моделью - мы по сути перешли к задаче регрессии (но можно и решать задачу классификации, только использовать соответствующую функцию потерь). А значит для каждой модели её параметры можно найти с помощью оптимизационной задачи (как и в регрессии): $\theta_t = argmin_{\theta} \Sum_{i=1}^n (r_i^{(i)} - h(x^{(i)}, \theta))^2$. Вид функции потерь является гиперпараметром, поэтому можно выбирать её как угодно. Тут антиградиент функции ошибки по предсказанию (который мы вычислили на всех прошлых моделях в ансамбле) мы хотим приблизить к выходу новой модели в ансамбле.

Просто когда мы используем квадратичную ошибку при задаче регрессии у нас антиградиенты являются просто разницей между истинным таргером и предсказанным.

А вес $\rho_t$ для новой модели мы можем либо задать константой, либо сделать значениями монотонноу убывающими, либо же найти из оптимизационной задачи: $\rho_t = argmin_{\rho} \Sum_{i=1}^n L(y^{(i)}, f_{t-1}(x^{(i)}) + \rho h_t(x^{(i)}, \theta_t))$.

Теперь мы можем добавить новую модель $f_t(x) = \rho_t h_t(x, \theta_t)$ в ансамбль и ожидать улучшения работы всего ансамбля.

https://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html - demo для gradient boosting.

КАЖДАЯ НОВАЯ МОДЕЛЬ УЧИТСЯ ПРЕДСКАЗЫВАТЬ АНТИГРАДИЕНТ ФУНКЦИИ ПОТЕРЬ ПРЕДЫДУЩЕГО АНСАМБЛЯ (НО ЭТО ВЕРНО ДЛЯ КАЖДОГО ОБЪЕКТА)! А ЗАТЕМ КАЖДАЯ МОДЕЛЬ УЧИТСЯ АППРОКСИМИРОВАТЬ ЭТОТ АНТИГРАДИЕНТ СРАЗУ ПО ВСЕЙ ВЫБОРКЕ.

В градиентном бустинге отдельно взятая модель (если она не первая) сама по себе не несет никакого смысла, так как она аппроксимирует антиградиент функции потерь по предсказаниям предыдущего ансамбля.

Градиентный бустинг эффективней, чем Random Forest, так как при Random Forest мы используем переобученные (глубокие) деревья и затем усредняем предсказания. Например, эффективность RF на 100 деревьев глубины 100 будет сравнима с 100 деревьями глубины 10 при градиентном бустинге. Однако, градиентный бустинг может переобучаться - это нужно учитывать. 


Итак, что нам нужно для градиентного бустинга:
1. Данные
2. Функция потерь и её градиент
3. Параметрическое семейство алгоритмов (с ограничениями если необходимо)
4. Число итераций бустинга (количество моделей в ансамбле)
5. Начальная модель (по Фридману - это константная модель)

# Тонкости Gradient Boosting
Random Forest может быть распараллелено по одному дереву на поток выполнения (так как все деревья в нем независимы). Это работает как на тренировке так и на инференсе. Допустим, при инференсе приходит запрос - мы считаем каждое дерево, и в случае даже если сервера с какими-то деревьями упали - это не особо страшно, предсказание всё равно будет более-менее хорошим.

В случае градиентного бустинга, при инференсе мы можем считать деревья параллельно (также как и в RF), но при обучении нам нужно их считать строго последовательно (и при этом если вдруг какое-то дерево упало при тренировке, то продолжить обучение не получится). 

Градиентный бустинг в сравнение с линейными моделями и с RF:
1. Лучше описывает сложные зависимости, так как он больше нацелен исправить все мелкие ошибки (путем последовательного вычисления антиградиента функции ошибки по предсказаниям) -> градиентный бустинг стремится переобучиться под тренировочные данные лучшим образом, даже больше чем другие алгоритмы, так как GB явно уменьшает ошибки предсказаний. КРАЙНЕ АККУРАТНО НУЖНО СЛЕДИТЬ ЗА ПЕРЕОБУЧЕНИЕМ ГРАДИЕНТНОГО БУСТИНГА

# Bias-variance tradeoff (practice0_05_ensembles.ipynb)
Ошибка раскладывается на смещение (bias - насколько точно мы можем описывать наши данные используя какую-то модель), разброс (variance - если модель имеет высокий variance, то она не устойчива в смысле того, что если мы чуть-чуть изменим выборку, то модель рискует существенно поменяться (а вместе с ней и её предсказания), таким свойством (высокий variance) обладают решающие деревья, мы как раз и использовали это свойство когда строили деревья на бутстрапированных выборках) и шум (noise - который просто есть в наших данных, обычно он несмещенный).

Грубо говоря:
1. Variance у нас высокий модель переобучилась под конкретные данные (если мы чуть-чуть поменяем данные, то модель будет другая)
2. Bias высокий когда модель слишком простая, чтобы корректно предсказывать данные
То есть у простых моделей *low variance-high bias*, а у сложных - *high variance-low bias*.

Именно поэтому у нас линейная комбинация моделей со слабо-скоррелированными ошибками позволяет понизить ошибку. Это происходит потому что у нас у каждой модели есть какая-то дисперсия, а когда мы берем сумму слабо-скоррелированных моделей то итоговая дисперсия равно сумме отдельных дисперсий моделей (формула: $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)$). А далее мы поделим предсказания моделей на их количество, то есть поделим и дисперсию (формула: $Var(aX) = a^2 Var(X)$) то есть итоговая дисперсия будет равна 1/N дисперсии одной модели.

Именно поэтому Bagging над линейными моделями не имеет смысла - так как у нинейных моделей low variance и high bias. А так как мат ожидание оно линейно, то после аггрегации нескольких моделей с помощью Bagging у нас всё равно bias финальной модели останется тем же.

Градиентный бустинг каждый раз повышает сложность итоговой модели (уменьшает bias), но он борется с ошибкой не с помощью усреднения variance как при бэггинге, RF (там куча переобученных моделей у которых low bias, high variance). То есть с увеличением шага в GB bias уменьшается, а variance растет. 
Также, следует указать, что сложность зависимости которую может описвать RF, такая же как и у одного DT. А при GB эта сложность расчтет.

Также GB над линейными моделями тоже не имеет смысла, так как при GB итоговой моделью является взвешенная сумма моделей. А линейная комбинация линейных моделей = линейная модель. То есть мы не сможем выбраться из класса линейных моделей.

При тренировки модели градиентного бустинга необходимо построить хороший пайплайн валидации и сохранять бенчмарки модели на каждых шагах. Так как если мы заметим переобучение, то сможем остановиться и откатиться к лучшей модели.

Помимо коэффициента $\rho_t$, который мы выбираем оптимально, решая задачу оптимизации, добавляют также коэффициент learning_rate, для того чтобы изменять его по убывающему закону и к концу обучения у нас решение не скакало около оптимума.