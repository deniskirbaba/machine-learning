# Boosting

Random Forest (RF) строит деревья параллельно, но бустинг предполагает последовательное обучение моделей.
Как можно "подключить" модели последовательно?
Интуиция следующая: на каждом шаге будем увеличивать вклад ошибки на неверно классифицированных объектах в итоговой функции потерь. Это достигается путём введения весов для объектов $\omega_i$, которые корректируются на каждом шаге, чтобы усилить влияние тех объектов, которые были неправильно классифицированы предыдущими моделями. Таким образом, каждая последующая модель сосредотачивается на "сложных" для предыдущих моделей примерах.

На каждом шаге последовательности (итерации бустинга) мы обновляем веса $\omega_i$ в зависимости от ошибки текущей модели и перерассчитываем их, чтобы усилить влияние ошибочно классифицированных объектов. В конце, чтобы получить финальную модель, мы агрегируем все модели, например, через взвешенное суммирование их предсказаний.

# AdaBoost

AdaBoost использует экспоненциальную функцию потерь вида $L(y, f(x)) = \exp(-y f(x))$, где $y$ — истинная метка объекта, а $f(x)$ — результат взвешенного предсказания текущей модели. Эта функция потерь усиливает вклад объектов, на которых текущая модель ошибается (когда знак $y f(x)$ отрицателен).

Итоговая модель в AdaBoost представляется как сумма взвешенных предсказаний базовых моделей:
$$
F(x) = \sum_{t=1}^{T} \rho_t h_t(x),
$$
где $\rho_t$ — вес (вклад) каждой базовой модели $h_t(x)$. Веса $\rho_t$ определяются в зависимости от того, насколько успешна модель $h_t$ на предыдущем шаге: чем лучше модель справляется с задачей, тем больший вклад она вносит в итоговую модель.

На каждом шаге функция потерь для объекта имеет две составляющие: константную часть (которая учитывает вклад всех предыдущих моделей) и экспоненциальную функцию потерь для текущей базовой модели. Эта экспоненциальная функция делает AdaBoost очень чувствительным к ошибкам на объектах: если ошибка велика, функция потерь сильно возрастает, что может привести к чрезмерному влиянию отдельных ошибочных объектов.

Базовыми моделями могут быть любые алгоритмы, но часто используют слабые модели, например, решающие пни (деревья глубины 1). Важно отметить, что экспоненциальная функция потерь может быть нестабильной: при больших ошибках она может резко увеличиваться, что делает алгоритм чувствительным к выбросам и шуму в данных.

## Важно:
AdaBoost — это не градиентный бустинг, хотя он может рассматриваться как его частный случай. В отличие от градиентного бустинга, который минимизирует произвольные дифференцируемые функции потерь, AdaBoost минимизирует экспоненциальную функцию потерь. С появлением градиентного бустинга, предложенного Фридманом, появилось множество новых вариантов бустинга, которые позволили гибко использовать разные функции потерь.

# Gradient Boosting

[Good material from catboost](https://catboost.ai/en/docs/concepts/algorithm-score-functions#gradient-boosting)

Наша цель в ML почти всегда заключается в построении модели $f(x)$, которая минимизирует функцию потерь $L(f(x), y)$ на обучающей выборке $(x_i, y_i)$. Задача заключается в нахождении такой модели, которая минимизирует эмпирический риск на обучающих данных и демонстрирует хорошую обобщающую способность на тестовой выборке.

Если у нас есть параметрическое семейство функций $f(x, \theta)$, то наша цель — найти параметры $\theta$, которые минимизируют функцию потерь:
$$
\hat{\theta} = \arg\min_{\theta} \sum_{i=1}^{n} L(f(x_i, \theta), y_i).
$$

Градиентный бустинг можно рассматривать как метод оптимизации в пространстве функций. Он минимизирует функцию потерь по предсказаниям модели с помощью градиентного спуска, но делает это поэтапно, добавляя на каждом шаге новую базовую модель.

На каждом шаге $t$ итоговая модель записывается как сумма всех предыдущих базовых моделей:
$$
f_T(x) = \sum_{t=1}^{T} \rho_t h_t(x),
$$
где $\rho_t$ — вес базовой модели $h_t(x)$, а $h_t(x)$ — базовая модель (например, дерево решений) с параметрами $\theta_t$. Каждая новая модель $h_t(x)$ обучается таким образом, чтобы аппроксимировать антиградиент функции потерь на текущем шаге.

## Градиентный спуск в пространстве функций

Градиентный бустинг можно рассматривать как градиентный спуск в функциональном пространстве, где каждый объект соответствует отображению $X \rightarrow Y$. На каждом шаге мы обновляем модель в направлении, противоположном градиенту функции потерь по предсказаниям модели.

Градиентный спуск в линейной регрессии, например, обновляет веса модели по следующему правилу:
$$
\omega_{t+1} = \omega_t - \eta \nabla_{\omega} L(f(x, \omega), y).
$$
В случае градиентного бустинга модель обновляется через добавление новой базовой модели, которая аппроксимирует антиградиент функции потерь:
$$
f_T(x) = f_{T-1}(x) + \rho_T h_T(x),
$$
где $h_T(x)$ обучается на аппроксимацию антиградиента функции потерь по предсказаниям $f_{T-1}(x)$.

## Антиградиент функции потерь

На каждом шаге $t$ для каждого объекта $x^{(i)}$ мы вычисляем предсказание текущей модели $f_t(x^{(i)})$ и антиградиент функции потерь по этому предсказанию:
$$
r_t^{(i)} = -\frac{\partial L(y^{(i)}, f_t(x^{(i)}))}{\partial f_t(x^{(i)})}.
$$
Этот антиградиент $r_t^{(i)}$ становится новым "таргетом" для базовой модели на следующем шаге. То есть на шаге $t$ новая модель $h_t(x)$ обучается на задачу регрессии, где таргет — это антиградиент по текущим предсказаниям.

Таким образом, на каждом шаге новая базовая модель обучается на приближение антиградиента функции потерь, что позволяет минимизировать эмпирический риск по шагам.

## Решение оптимизационной задачи

Когда мы аппроксимируем антиградиент функции потерь с помощью базовой модели, мы по сути решаем задачу регрессии. Параметры $\theta_t$ модели $h_t(x)$ определяются через минимизацию ошибки на каждом шаге:
$$
\theta_t = \arg\min_{\theta} \sum_{i=1}^{n} (r_t^{(i)} - h(x^{(i)}, \theta))^2.
$$
Функция потерь может быть разной в зависимости от задачи, и её выбор — это гиперпараметр модели.

Для задачи регрессии с квадратичной функцией потерь антиградиент ошибки совпадает с разницей между истинным значением $y^{(i)}$ и предсказанием $f_t(x^{(i)})$.

## Оптимизация веса новой модели

Вес $\rho_t$ новой базовой модели можно найти через оптимизационную задачу:
$$
\rho_t = \arg\min_{\rho} \sum_{i=1}^{n} L\left(y^{(i)}, f_{t-1}(x^{(i)}) + \rho h_t(x^{(i)}, \theta_t)\right).
$$
Также можно задать $\rho_t$ константой или уменьшать его монотонно с каждым шагом. После этого новая модель $f_t(x) = \rho_t h_t(x)$ добавляется в ансамбль.

## Примечания

1. **Градиентный бустинг** — это итеративный процесс, где каждая новая модель учится аппроксимировать антиградиент функции потерь по предсказаниям предыдущего ансамбля. Этот процесс повторяется до тех пор, пока не будет добавлено заданное количество базовых моделей или ошибка не станет достаточно маленькой.
   
2. Каждая отдельная базовая модель, если она не первая, сама по себе не имеет смысла, так как она обучается на предсказания предыдущего ансамбля и аппроксимирует антиградиент.

3. **Градиентный бустинг эффективнее Random Forest** на глубине деревьев, так как в RF деревья строятся независимо и затем усредняются, а в градиентном бустинге каждое новое дерево исправляет ошибки предыдущего. Однако градиентный бустинг более чувствителен к переобучению.

## Важные составляющие градиентного бустинга

1. Данные.
2. Функция потерь и её градиент.
3. Параметрическое семейство базовых моделей (например, деревья решений).
4. Число итераций бустинга (количество моделей в ансамбле).
5. Начальная модель (по умолчанию — константная модель).

[Подробное объяснение градиентного бустинга на Python с примером](https://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html).

## Тонкости Gradient Boosting

**Random Forest** можно легко распараллелить, так как все деревья в нем независимы. Это применимо как на этапе тренировки, так и на этапе инференса. Например, при инференсе мы можем параллельно считать предсказания всех деревьев. Даже если часть серверов с отдельными деревьями выйдет из строя, итоговое предсказание останется достаточно точным, так как основано на усреднении предсказаний множества деревьев.

В **градиентном бустинге** при инференсе также возможно параллельное вычисление предсказаний всех деревьев, как и в Random Forest. Однако на этапе обучения деревья должны строиться **строго последовательно**: каждое последующее дерево корректирует ошибки предыдущего. Это значит, что если одно дерево не было корректно обучено, обучение всей модели невозможно продолжить. Градиентный бустинг требует завершения каждого шага обучения для корректной работы следующего.

## Сравнение градиентного бустинга с линейными моделями и Random Forest

1. **Модель лучше описывает сложные зависимости.** Градиентный бустинг последовательно минимизирует ошибки предсказаний за счёт того, что каждое новое дерево обучается на ошибках предыдущего. Это позволяет ему эффективно захватывать сложные паттерны в данных. Однако именно из-за этого градиентный бустинг склонен к переобучению. Так как каждая новая модель активно исправляет ошибки предсказаний предыдущих, он может "подгоняться" под тренировочные данные слишком точно. Это требует особенно тщательного контроля за переобучением через использование регуляризации, early stopping и корректного подбора гиперпараметров (например, глубины деревьев).

2. **Входные данные $X$ не изменяются, но целевое пространство меняется на каждом шаге.** В градиентном бустинге на каждом шаге не изменяются сами признаки (входное пространство $\mathbb{X}$), но меняется целевое пространство: каждая новая модель пытается предсказать антиградиент ошибки по предсказаниям предыдущей модели. Таким образом, для модели $h_t(x)$ на шаге $t$, целевое пространство $Y_t$ соответствует антиградиенту функции потерь по предсказаниям предыдущей модели $f_{t-1}(x)$:
   $$
   f_t: \mathbb{X} \rightarrow \mathbb{Y}_t.
   $$
   Это ключевая особенность градиентного бустинга — каждая новая модель исправляет ошибки всех предыдущих через пересчёт целевого значения.

## Ансамбли над различными моделями

GB над линейными моделями не имеет смысла, так как при GB итоговой моделью является взвешенная сумма моделей. А линейная комбинация линейных моделей = линейная модель. То есть мы не сможем выбраться из класса линейных моделей.

GB над логистическими регрессиями имеет смысл, так как мы получаем комбинацию нелинейных моделей, тем самым мы композицией слабых классификатором выходим за класс линейных оценок.

## Интересный вопрос

Обучение базовой модели на антиградиент функции потерь, а не просто на разницу между истинными значениями и предсказаниями ансамбля, объясняется глубокой связью с оптимизацией и работой с произвольными функциями потерь.

### Причины, почему мы используем антиградиент:

1. **Общность и гибкость для любых функций потерь**:
   - Градиентный бустинг применим не только к задачам с MSE (среднеквадратичной ошибкой), но и к другим функциям потерь (например, логистическая функция для классификации или Huber loss). Если бы мы обучали на простую разницу между истинными значениями и предсказаниями, то такая схема работала бы только для MSE. 
   - Использование **антиградиента функции потерь** позволяет адаптировать градиентный бустинг к любой дифференцируемой функции потерь, делая его универсальным.

2. **Градиент — это направление наилучшего улучшения**:
   - В задачах оптимизации градиент указывает направление, в котором ошибка уменьшается быстрее всего. Обучая новую базовую модель на антиградиенте, мы гарантируем, что на каждом шаге бустинг будет двигаться в направлении уменьшения ошибки наиболее эффективно.
   - Разница между истинными значениями и предсказаниями ансамбля не обязательно будет направлена туда, где функция потерь уменьшается быстрее всего. Антиградиент же указывает именно это направление.

3. **Корректное обучение для нелинейных моделей**:
   - В реальных задачах мы часто используем сложные нелинейные функции потерь, для которых прямая разница между предсказанием и реальным значением не всегда отражает истинную степень ошибки. Например, в логистической регрессии разница между вероятностями не эквивалентна логистической потере. 
   - Обучая базовую модель на антиградиенте функции потерь, мы корректно учитываем, как ошибка изменяется для нелинейных моделей и функций потерь.

### Пример с MSE:
- В случае MSE (среднеквадратичной ошибки) антиградиент действительно совпадает с разницей между истинными значениями и предсказаниями. Это видно из вычисления градиента:
  $$
  L = \frac{1}{2}(y - f(x))^2 \quad \Rightarrow \quad \frac{\partial L}{\partial f(x)} = f(x) - y.
  $$
  Однако для других функций потерь это уже не так.

### Заключение:
Использование антиградиента функции потерь делает градиентный бустинг **универсальным инструментом** для решения задач с произвольной функцией потерь, и позволяет каждой новой базовой модели оптимизировать ошибку в наилучшем направлении.

# Bias-Variance Tradeoff

При анализе ошибки модели её можно разложить на три составляющие: **смещение (bias)**, **разброс (variance)** и **шум (noise)**.

- **Bias (смещение)** — это мера того, насколько хорошо модель описывает истинную зависимость в данных. Высокий bias означает, что модель слишком упрощённая и не способна правильно захватывать сложные закономерности (например, слишком простая линейная модель).
- **Variance (разброс)** — это мера чувствительности модели к изменениям в обучающих данных. Модель с высоким variance нестабильна: при небольших изменениях данных она сильно изменяет свои предсказания. Такое свойство присуще сложным моделям, например, решающим деревьям, которые склонны переобучаться.
- **Noise (шум)** — это случайная ошибка, присущая данным. Шум нельзя устранить с помощью моделей, он присутствует в данных независимо от их структуры и не зависит от параметров модели.

## Ключевые моменты:
1. **Высокий variance** означает, что модель переобучилась на конкретные данные. Если данные немного изменятся, модель даст существенно другие результаты.
2. **Высокий bias** указывает на то, что модель слишком простая для адекватного представления зависимостей в данных (например, линейные модели на сложных данных).

Таким образом, **простые модели** имеют **низкий variance** и **высокий bias**, в то время как **сложные модели** обладают **высоким variance** и **низким bias**.

## Почему ансамбли моделей снижают ошибку?

Ансамбли, состоящие из слабо коррелированных моделей, позволяют уменьшить variance и, следовательно, общую ошибку. Это происходит потому, что каждая модель вносит свою дисперсию в общее предсказание, но за счёт усреднения предсказаний нескольких моделей дисперсия уменьшается.

- Формула для суммы дисперсий двух моделей: 
  $$
  Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y).
  $$
  Если модели слабо скоррелированы, $Cov(X, Y)$ близка к нулю, и итоговая дисперсия уменьшается.

- Когда мы усредняем предсказания $N$ моделей, итоговая дисперсия уменьшается в $N$ раз:
  $$
  Var(aX) = a^2 Var(X), \text{ где } a = \frac{1}{N}.
  $$
  Это значит, что общий разброс ансамбля снижается, улучшая стабильность предсказаний.

Именно поэтому **bagging** (например, Random Forest) эффективен для моделей с высоким variance и низким bias, таких как решающие деревья. Усреднение их предсказаний приводит к снижению variance. Однако **bagging линейных моделей** не имеет смысла, так как они уже обладают низким variance и высоким bias. Усреднение их предсказаний не улучшит bias, который остаётся неизменным.

## Градиентный бустинг и его влияние на bias и variance

В **градиентном бустинге** каждая новая модель добавляет сложность в итоговую модель, что уменьшает bias. Однако, в отличие от бэггинга и Random Forest, где основной акцент делается на уменьшении variance, градиентный бустинг нацелен на последовательное уменьшение ошибки. С каждым новым шагом обучения bias снижается, но при этом растёт variance.

- Важная особенность: сложность зависимости, которую может описывать Random Forest, эквивалентна сложности одного решающего дерева. В то время как в градиентном бустинге сложность итоговой модели увеличивается с каждым шагом добавления новых моделей.

## Валидация и предотвращение переобучения

Так как градиентный бустинг склонен к переобучению, особенно при большом количестве шагов, важно использовать грамотный процесс валидации и отслеживания результатов на каждом этапе обучения. Хорошей практикой является **early stopping** — остановка обучения при первых признаках переобучения, с возможностью отката к лучшей модели.

## Регулировка шага обучения (learning rate)

Кроме коэффициента $\rho_t$, который подбирается оптимизационными методами, в градиентном бустинге часто вводят **коэффициент скорости обучения (learning rate)**. Этот коэффициент позволяет контролировать вклад каждой новой модели в итоговую модель. Уменьшение learning rate к концу обучения помогает избежать резких изменений и колебаний около оптимального решения.