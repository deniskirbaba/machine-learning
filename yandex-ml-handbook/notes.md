# Notes from Yandex ML Handbook

## Introduction

Перед решением задачи необходимо определить к какому виду относится задача (классификация, регрессия, кластеризация...).

Далее выбираем метрику качества. Они имеют следующую иерархию:
1. Бизнес-метрики - показатели работы всей системы в целом, обычно они зависят не только от качества работы разработанной модели. Например, доход с торговой точки
2. Online-метрики - покатели работающей системы, которые высчитывают в реальном времени после внедрения модели. Например, медианное время проведенное в игре пользователем.
3. Ассесоры - показатели, оцененные специальными людьми - ассесорами (тестировщиками). Например, тестировщики оцениват качество ответа языковой модели. 
4. Offline-метрики - метрики, рассчитываемые при разработке модели, например используя исторические данные. Здесь мы используем классические метрики машинного обучения.

Также важно обратить внимание на данные, которые будут использованы при разработке модели. Являются ли они размеченными или нет, какого они вида (требуется ли feature engineering или representation learning), сколько у нас данных и какого они качества. Также отметим некоторые проболемы в данных, которые часто встречаются:
1. Пропуски
2. Выбросы
3. Ошибки разметки
4. Data drift

Далее выбираем модель и алгоритм её обучения. 

Важен и этап деплоймента модели. Необходимо эффективно запрограммировать модель и успешно встроить её в уже существующую систему. И подумать как и какие рассчитывать online-метрики. Также имеет смысл провести АБ-тестирование, то есть сравнение с предыдущей версией модели на случайно выбранных подмножествах пользователей или сессий. Если новая модель работает не очень здорово, должна быть возможность откатиться к старой.

После деплоймента модели важно продолжать дообучать или переобучать её при поступлении новых данных, а также мониторить качество. Существует concept drift — изменение зависимости между признаками и таргетом. Например, если вы делаете музыкальные рекомендации, вам нужно будет учитывать и появление новых треков, и изменение вкусов аудитории.

Data scientists обычно выбирают одни метрики для наблюдения за тренировкой модели и другой набор метрики при представлении результатов работы модели для работодателей/бизнеса и т.д. При этом выбор таких метрик должен основываться на следующих параметрах:
1. Насколько много выбросов в данных и как мы хотим их учитывать
2. Если разница между overforecating и unforecasting, и если она есть, каким образом мы будем её оценивать
3. Scale-dependent (MAE, MSE) и scale-independent (R2, NMAE). Scale-dependent изменяются при изменении величины данных, их удобно использовать для оценки общих ошибок в шкале единиц измерения таргета на каком-либо датасете, имеющим одну шкалу. Scale-independent используют нормализацию в каком-либо виде и поэтому не зависят от шкал данных, они удобны для сравнения работы модели на различных датасетах, имеющиъ различные шкалы.

При выборе метрик в задаче классификации следует опираться на следующее:
1. Распределение объектов по классам (сбалансированная выборка или нет). Для сбалансированных выборок хорошо подходит метрика accuracy, для несбалансированных presicion, recall, F1-score, area under the precision-recall curve (AUPRC)
2. Важность типа ошибок (ошибки 1-го рода или ошибки 2-го рода важнее). Исходя из важности можно смотреть на precision, recall или f1-score
3. Интерпретируемость для бизнеса
4. Цель модели. Важно ли нам создать обощенную модель (которая будет достаточно хорошо определять каждый класс) или же узко-направленную модель (которая будет хорошо определять только 1 конкретный класс). В зависимости от этого важность метрик будет различаться
5. Threshold sensibility. Метрика AUPRC не зависит от порога вероятности предсказания класса 
6. Количество классов (бинарная классификация или многоклассовая). В зависимости от этого confusion matrix, accuracy, precision, recall, f1-score могут быть адаптированы для многоклассовой классификации, используя macro, micro, weighted averages
7. Вычислительная сложность

Common Metrics for Classification
Binary Classification Metrics:
1. Accuracy: Proportion of correctly classified instances.
2. Precision: Proportion of true positive predictions among all positive predictions.
3. Recall (Sensitivity): Proportion of true positive predictions among all actual positives.
4. F1-Score: Harmonic mean of Precision and Recall, balancing the two.
5. AUROC (Area Under ROC Curve): Measures the ability of the model to distinguish between classes.
6. AUPRC (Area Under Precision-Recall Curve): Useful for imbalanced datasets.
7. Confusion Matrix: Provides counts of true positives, true negatives, false positives, and false negatives.
Multi-class Classification Metrics:
1. Accuracy: Overall correctness.
2. Precision, Recall, F1-Score: Can be computed for each class and averaged (macro, micro, weighted).
3. Confusion Matrix: Extended for multiple classes.
4. Logarithmic Loss (Log Loss): Measures the uncertainty of predictions.
5. Cohen’s Kappa: Measures the agreement between predicted and actual classes, adjusted for chance.

При адаптации метрик бинарной классификации к многоклассовой производится вычисление метрик для каждого класса и затем их усреднение по различному виду: macro, micro, weighted:
1. Macro - независимо рассчитываем метрику для каждого класса и затем берем среднее арифметическое по всем классам. macro_f1 = 1/N (sum of f1 for each class). Используем macro в случае несбалансированных классов. Хорошо подходит для получения представления об оценки по каждому классу, особенно если размеры классов одинаковы
2. Micro - представляет, что перед нами задача классификации и аггрегирует TP, FP, FN для всех классов. Используем micro в случае сбалансированных классов. Однако данный случай хорошо подходит для общей оценки, особенно когда размеры классов значительно отличаются.
3. Weighted - высчитывает независимо метрику для каждого класса и затем берем среднее с учетом количество объектов из каждого класса. Полезно при работе с несбалансированными наборами данных, чтобы убедиться, что большие классы не доминируют в метрике

## Линейные модели

Преимущество линейных моделей является их интерпретируемость, так как по значениям весов можно судить о важности признака и о влиянии его на таргет. Однако интерпретируемость может сильно снизиться, если избыточно применять feature engineering - добавив большое число сложных дополнительных фичей.

При разговоре о важности признака (на основе значения веса) необходимо учитывать его масштаб.

Функция, показывающая насколько часто наша модель ошибается называется функцией потерь, функционалом качества или loss function. От её выбора зависит то, насколько задачу в дальнейшем легко решать, и то, в каком смысле у нас получится приблизить предсказание модели к целевым значениям.

При решении задачи регресии с помощью линейной модели, используя метод наименьших квадратов (ordinary least squares), с точки зрения статичестики это соответствует гипотезе о том, что наши данные состоят из линейного "сигнала" и нормально распределенного "шума".

Функционал - это отображение, которое принимает на вход функцию и возвращает число. MSE(f, X, y) является функционалом.

При аналитическом решении линейной регрессии с MSE, получается w* = (X^TX)^-1 X^T y. Из линейной алгебры известно, что ранг X^TX и X одинаков. А значит матрица X^TX будет невырождена и, соответственно, обратимо в случае если в матрице X не будет линейно зависимых признаков. Однако зачастую в ML матрица X имеет приближенно зависимые столбцы признаков и это приводит к нестабильным решениям. В подобных случаях погрешность нахождения w* будет зависеть от квадрата числа обусловленности матрицы X, что очень плохо. Это делает полученное таким образом решение численно неустойчивым: малые возмущения y могут приводить к катастрофическим изменениям w*.

Число обусловленности (condition number) вычисляется как отношение максимального и минимального сингулярных (собственных) чисел матрицы.

Вычислительная сложность градиентного спуска O(NDS), а у аналитического решения O(N^2D + D^3), где N - число элементов выборки, D - число признаков, S - число итераций градиентного спуска. 

Стохастический градиент на каждом шаге вычисляет градиент не по всему датасету (сложность O(ND)), а по его подвыборке (батчу). 

Выборку делят на батчи путем изначального её перемешивания а затем просто берут по порядку батчи. Эпоха - это один полный проход семплера по выборке.

Шаги стохастического градиентного спуска заметно более шумные, но считать их получается значительно быстрее. В итоге они тоже сходятся к оптимальному значению из-за того, что матожидание оценки градиента на батче равно самому градиенту.

Преимуществом стохастического градиентного спуска является то, что в оперативной памяти требуется держать не всю выборку, а лишь батч.

Существует определённая терминологическая путаница, иногда стохастическим градиентным спуском называют версию алгоритма, в которой размер батча равен единице (то есть максимально шумная и быстрая версия алгоритма), а версии с бОльшим размером батча называют batch gradient descent.

Мультиколлинеарность признаков - это приближенная линейная зависимость признаков. Для того, чтобы справиться с этой проблемой, задачу обычно регуляризуют, то есть добавляют к ней дополнительное ограничение на вектор весов.

L2-регуляризация работает прекрасно и используется в большинстве случаев, но есть одна полезная особенность L1-регуляризации: её применение приводит к тому, что у признаков, которые не оказывают большого влияния на ответ, вес в результате оптимизации получается равным 0. Это позволяет удобным образом удалять признаки, слабо влияющие на таргет. Кроме того, это даёт возможность автоматически избавляться от признаков, которые участвуют в соотношениях приближённой линейной зависимости, соответственно, спасает от проблем, связанных с мультиколлинеарностью.

В задаче линейной классификации мы хотим минимизировать число ошибок предказаний класса. 

В простейшем случае можно выразить величину отступа (margin) M = y_i * (w, x_i). Число неверных классификаций - misclassification loss. Так как эта функция - кусочно-постоянная, то её нельзя оптимизировать градиентными методами (в каждой точке производная = 0). Поэтому есть смысл приближения этой функции другими гладкими функциями. 

Например: 
1. Ошибка перцептрона: F(M) = max(0, -M). Однако в случае минимизации функционала потерь основанной на данной функции потерь решение не единственно. Для таких случаев, возникает логичное желание не только найти разделяющую прямую, но и постараться провести её на одинаковом удалении от обоих классов, то есть максимизировать минимальный отступ. Это делает Hinge loss.
2. Hinge loss (SVM): F(M) = max(0, 1 - M). Итоговое положение плоскости задаётся всего несколькими обучающими примерами. Это ближайшие к плоскости правильно классифицированные объекты, которые называют опорными векторами или support vectors. Весь метод, соответственно, зовётся методом опорных векторов, или support vector machine, или сокращённо SVM.

Если решать задачу классификацию как задачу регресии, то это называется логистической регрессией. 

Тут используется вероятностная природа принадлежности объекта к одному или другому классу. Однако так как функция вероятности имеет область значений [0, 1] потребуются дополнительные модификации для применения регрессии. Из этой ситуации можно выйти так: научить линейную модель правильно предсказывать какой-то объект, связанный с вероятностью, но с диапазоном значений (-inf, +inf), и преобразовать ответы модели в вероятность. Таким объектом является logit или log odds – логарифм отношения вероятности положительного события к отрицательному $log(p/(1-p))$. 

То есть $(w, x_i) = log(p/(1-p))$, а следовательно $p = 1/(1+e^(-(w, x_i)) = \sigma((w, x_i))$.

Как теперь научиться оптимизировать $w$ так, чтобы модель как можно лучше предсказывала логиты? Нужно применить метод максимума правдоподобия для распределения Бернулли. С помощью этого мы находим требуемый функционал потерь, для которого потом рассчитываем градиент и используем градиентный метод для поиска минимума.

Предсказания такой модели будут вычисляться как $p = \sigma((w, x_i))$. Порог вероятности подбирается отдельно, для уже построенной регрессии, минимизируя нужную нам метрику на отложенной тестовой выборке. Например, сделать так, чтобы доля положительных и отрицательных классов примерно совпадала с реальной.

Отдельно заметим, что метод называется логистической регрессией, а не логистической классификацией именно потому, что предсказываем мы не классы, а вещественные числа – логиты.

Для решения задачи многоклассовой классификации линейными моделями мы сводим её к набору задач бинарной классификации. Есть два популярных метода это сделать one-vs-all и all-vs-all.

В случае one-vs-all мы обучаем K (количество классов) линейных бинарных классификаторов, каждый из которых предсказывает метку одного из классов: $b_k(x) = sign((w_k, x) + w_{0k})$. Каждый классификатор учится отделять свой класс от остальных. 

Логично, чтобы итоговый классификатор выдавал класс, соответствующий самому уверенному из бинарных алгоритмов. Уверенность можно в каком-то смысле измерить с помощью значений линейных функций: $argmax_k((w_k, x) + w_{0k})$.

Проблема данного подхода заключается в том, что каждый из классификаторов $b_k$ обучается на своей выборке, и значения линейных функций $(w_k, x) + w_{0k}$ или, проще говоря, "выходы" классификаторов могут иметь разные масштабы. Из-за этого сравнивать их будет неправильно. Нормировать вектора весов, чтобы они выдавали ответы в одной и той же шкале, не всегда может быть разумным решением: так, в случае с SVM веса перестанут являться решением задачи, поскольку нормировка изменит норму весов.

В случае all-vs-all мы обучаем $C^2_k$ классификаторов. Каждый классификатор (в случае линейных моделей) имеет вид $b_{ij}(x) = sign((w_{ij}, x) + w_{0ij}), i \neq j$.

Классификатор $a_{ij}(x)$ будем настраивать только по подвыборке $X_{ij}$, содержащей только объекты класса $i, j$. Чтобы классифицировать новый объект, подадим его на вход каждого из построенных бинарных классификаторов. Каждый из них проголосует за свой класс; в качестве ответа выберем тот класс, за который наберется больше всего голосов: $a(x) = argmax_k \sum_{i = 1}^K \sum_{i \neq j} I[a_{ij}(x) = k]$. 

Бинарную логистическую регрессию можно обобщить на многоклассовую. Допустим мы построили $K$ моделей, которые выдают логиты, которые мы потом переводим в вероятности принадлежности к какому-то одному классу. Для одновременного преобразования логитов от каждой модели в вероятности каждого класса можно использовать softmax, который производит нормировку вектора логитов. Обучать веса моделей предлагается с помощью метода максимального правдоподобия: так же, как и в случае с двухклассовой логистической регрессией.

Для увеличения масштабируемости линейных моделей по количеству фичей можно использовать разреженное кодирование, то есть вместо плотного вектора хранить словарь, в котором будут перечислены индексы и значения ненулевых элементов вектора.

Выводы:
1. На линейную модель можно смотреть как на однослойную нейросеть, поэтому многие методы, которые были изначально разработаны для них, сейчас переиспользуются в задачах глубокого обучения, а базовые подходы к регрессии, классификации и оптимизации вообще выглядят абсолютно так же. Так что несмотря на то, что в целом линейные модели на сегодня применяются редко, то, из чего они состоят и как строятся, знать очень и очень полезно.
2. Решение любой ML-задачи состоит из выбора функции потерь, параметризованного класса моделей и способа оптимизации.